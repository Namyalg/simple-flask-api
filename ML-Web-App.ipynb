{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": [],
      "mount_file_id": "1K2PfRNJjKBuy5S80yil7OqKzN56WXNK5",
      "authorship_tag": "ABX9TyOJFwutfXoPca3HO21y5wgO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namyalg/simple-flask-api/blob/main/ML-Web-App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJFLgoCgrQcK"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Train the classification model\n",
        "def train_model():\n",
        "    df = pd.read_json('intent_data.json')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['Utterance'], df['Intent'], random_state=0)\n",
        "\n",
        "    count_vect = CountVectorizer()\n",
        "    X_train_counts = count_vect.fit_transform(X_train)\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "    model = LinearSVC().fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Save the vectorizer\n",
        "    vec_file = 'vectorizer.pickle'\n",
        "    pickle.dump(count_vect, open(vec_file, 'wb'))\n",
        "\n",
        "    # Save the model\n",
        "    mod_file = 'classification.model'\n",
        "    pickle.dump(model, open(mod_file, 'wb'))\n",
        "\n",
        "\n",
        "# Load the classification model from disk and use for predictions\n",
        "def classify_utterance(utt):\n",
        "    # load the vectorizer\n",
        "    loaded_vectorizer = pickle.load(open('vectorizer.pickle', 'rb'))\n",
        "\n",
        "    # load the model\n",
        "    loaded_model = pickle.load(open('classification.model', 'rb'))\n",
        "\n",
        "    # make a prediction\n",
        "    print(loaded_model.predict(loaded_vectorizer.transform([utt])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d15qIRyoLnnv",
        "outputId": "fdebbd6f-f5fc-42df-f3d8-965a1cc10ff2"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "def train_naive():\n",
        "  cases = []\n",
        "  tags = []\n",
        "  serial = []\n",
        "  c = 1\n",
        "  n = []\n",
        "  with open('/content/drive/MyDrive/PROJECT-FIR/Latest-datasets/merged.csv', 'r') as file:\n",
        "      reader = csv.reader(file)\n",
        "      for row in reader:\n",
        "        try:\n",
        "          cases.append(row[0])\n",
        "          tg = row[1].lower().strip()\n",
        "          tags.append(tg)\n",
        "        except:\n",
        "          pass\n",
        "        w = row \n",
        "\n",
        "\n",
        "  main_class = []\n",
        "  for row in tags:\n",
        "    r = row.split(\",\")\n",
        "    main_class.append(r[0].strip())\n",
        "\n",
        "\n",
        "  classes = main_class\n",
        "  train_cases, test_cases, train_target, test_target = train_test_split(cases, classes, test_size=0.2, stratify = classes, shuffle = True, random_state=42)\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  cv = CountVectorizer(strip_accents=\"ascii\", token_pattern=u\"(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b\", lowercase=True, stop_words=\"english\")\n",
        "\n",
        "\n",
        "  X_train_cv = cv.fit_transform(train_cases)\n",
        "  X_test_cv = cv.transform(test_cases)\n",
        "\n",
        "  from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "  from sklearn.naive_bayes import MultinomialNB\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  #cv = CountVectorizer(strip_accents=\"ascii\", token_pattern=u\"(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b\", lowercase=True, stop_words=\"english\")\n",
        "\n",
        "  naive_bayes = MultinomialNB(alpha=0.4)\n",
        "  model = naive_bayes.fit(X_train_cv, train_target)\n",
        "  predictions = naive_bayes.predict(X_test_cv)\n",
        "\n",
        "    \n",
        "  y_test = test_target\n",
        "  print(\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
        "\n",
        "  vec_file = 'vectorizer.pickle'\n",
        "  pickle.dump(cv, open(vec_file, 'wb'))\n",
        "\n",
        "  # Save the model\n",
        "  mod_file = 'classification.model'\n",
        "  pickle.dump(model, open(mod_file, 'wb'))\n",
        "\n",
        "\n",
        "\n",
        "train_naive()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q22GXgApM8qR"
      },
      "source": [
        "def classify_utterance(utt):\n",
        "    # load the vectorizer\n",
        "    loaded_vectorizer = pickle.load(open('/content/drive/MyDrive/PROJECT-FIR/vectorizer.pickle', 'rb'))\n",
        "\n",
        "    # load the model\n",
        "    loaded_model = pickle.load(open('/content/drive/MyDrive/PROJECT-FIR/classification.model', 'rb'))\n",
        "\n",
        "    # make a prediction\n",
        "    print(loaded_model.predict(loaded_vectorizer.transform([utt])))\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUAmJniCNEF7"
      },
      "source": [
        "!cp /content/classification1.model /content/drive/MyDrive/PROJECT-FIR\n",
        "\n",
        "!cp /content/vectorizer1.pickle /content/drive/MyDrive/PROJECT-FIR"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV93a4nEL2lE"
      },
      "source": [
        "content = dict()\n",
        "cases = []\n",
        "tags = []\n",
        "serial = []\n",
        "c = 1\n",
        "n = []\n",
        "with open('/content/drive/MyDrive/PROJECT-FIR/Latest-datasets/merged.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "      try:\n",
        "        cases.append(row[0])\n",
        "        tg = row[1].lower().strip()\n",
        "        tags.append(tg)\n",
        "      except:\n",
        "        pass\n",
        "      w = row \n",
        "\n",
        "\n",
        "main_class = []\n",
        "for row in tags:\n",
        "  r = row.split(\",\")\n",
        "  main_class.append(r[0].strip())\n",
        "\n",
        "\n",
        "classes = main_class"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6WRlQ0OYHp"
      },
      "source": [
        "Other dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw9Y3KpIL3pK",
        "outputId": "53c6b3b1-b377-4340-ad33-498c2e1572a8"
      },
      "source": [
        "\n",
        "\n",
        "def train_n():\n",
        "\n",
        "  xtrain = []\n",
        "  ytrain = []\n",
        "\n",
        "  with open('/content/drive/MyDrive/PROJECT-FIR/Latest-datasets/Train_new_trial.csv', 'r') as file:\n",
        "      reader = csv.reader(file)\n",
        "      for row in reader:\n",
        "        xtrain.append(row[1])\n",
        "        ytrain.append(row[0])\n",
        "\n",
        "  xtest = []\n",
        "  ytest = []\n",
        "\n",
        "\n",
        "  with open('/content/drive/MyDrive/PROJECT-FIR/Latest-datasets/Book1.csv', 'r') as file:\n",
        "      reader = csv.reader(file)\n",
        "      for row in reader:\n",
        "        xtest.append(row[1])\n",
        "        ytest.append(row[0])\n",
        "\n",
        "  print(len(xtrain), len(ytrain))\n",
        "  print(len(xtest), len(ytest))\n",
        "  #classes = main_class\n",
        "  #train_cases, test_cases, train_target, test_target = train_test_split(cases, classes, test_size=0.2, stratify = classes, shuffle = True, random_state=42)\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  cv = CountVectorizer(strip_accents=\"ascii\", token_pattern=u\"(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b\", lowercase=True, stop_words=\"english\")\n",
        "\n",
        "\n",
        "  X_train_cv = cv.fit_transform(xtrain)\n",
        "  X_test_cv = cv.transform(xtest)\n",
        "\n",
        "  from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "  from sklearn.naive_bayes import MultinomialNB\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  #cv = CountVectorizer(strip_accents=\"ascii\", token_pattern=u\"(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b\", lowercase=True, stop_words=\"english\")\n",
        "\n",
        "  naive_bayes = MultinomialNB(alpha=0.4)\n",
        "  model = naive_bayes.fit(X_train_cv, ytrain)\n",
        "  predictions = naive_bayes.predict(X_test_cv)\n",
        "\n",
        "  print(\"Accuracy score: \", accuracy_score(ytest, predictions))\n",
        "\n",
        "  vec_file = 'vectorizer1.pickle'\n",
        "  pickle.dump(cv, open(vec_file, 'wb'))\n",
        "\n",
        "  # Save the model\n",
        "  mod_file = 'classification1.model'\n",
        "  pickle.dump(model, open(mod_file, 'wb'))\n",
        "\n",
        "\n",
        "\n",
        "train_n()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4778 4778\n",
            "124 124\n",
            "Accuracy score:  0.9435483870967742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FSjjvPIO6mo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}